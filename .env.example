# ============================================================================
# MSA Metadata Extractor - Environment Variables Configuration
# ============================================================================
# Copy this file to .env and update with your actual values
# Never commit .env to version control (it's in .gitignore)
# ============================================================================

# ============================================================================
# REQUIRED: API Configuration
# ============================================================================

# Gemini API Key (REQUIRED)
# Get your API key from: https://makersuite.google.com/app/apikey
GEMINI_API_KEY=

# ============================================================================
# Gemini Model Configuration
# ============================================================================

# Text LLM model for metadata extraction from text
# Options: gemini-2.5-pro, gemini-2.5-flash, gemini-1.5-pro, gemini-1.5-flash
GEMINI_TEXT_MODEL=gemini-2.5-pro

# Vision LLM model for image-based extraction and multimodal input
# Options: gemini-2.5-pro, gemini-2.5-flash, gemini-1.5-pro, gemini-1.5-flash
GEMINI_VISION_MODEL=gemini-2.5-pro

# ============================================================================
# FastAPI Server Configuration
# ============================================================================

# FastAPI server host (0.0.0.0 for all interfaces, 127.0.0.1 for localhost only)
API_HOST=0.0.0.0

# FastAPI server port
API_PORT=8000

# Number of worker processes (for production, use 4-8 workers)
API_WORKERS=1

# Enable auto-reload (for development only, set to false in production)
API_RELOAD=false

# Maximum file upload size in MB (default: 25MB)
MAX_UPLOAD_SIZE_MB=25

# Maximum concurrent background extraction tasks (default: 5)
API_MAX_CONCURRENT_EXTRACTIONS=5

# ============================================================================
# API Authentication Configuration
# ============================================================================

# Enable API key authentication (set to true for production)
# When enabled, all API requests must include a valid API key
API_ENABLE_AUTH=false

# API key(s) for authentication (required if API_ENABLE_AUTH=true)
# Single key: API_KEY=your-secret-key-here
# Multiple keys (comma-separated): API_KEY=key1,key2,key3
#   - Any key in the list will be accepted
#   - Useful for key rotation or multiple clients
# Generate a strong, random key (e.g., using: openssl rand -hex 32)
# Pass in request header: X-API-Key: <your-api-key>
# Or query parameter: ?api_key=<your-api-key> (less secure, for testing only)
API_KEY=

# ============================================================================
# Extraction Configuration (NEW ARCHITECTURE)
# ============================================================================

# Extraction Method: How to extract content from PDF pages
# Options:
#   - text_direct: Extract text directly from text pages, ignore image pages
#   - ocr_all: Convert all pages to images and run OCR on all pages
#   - ocr_images_only: Extract text from text pages + OCR only image pages (default)
#   - vision_all: Convert all pages to images (no OCR, for vision LLM)
#   - hybrid: Extract text from text pages + convert image pages to images (flexible)
EXTRACTION_METHOD=hybrid

# LLM Processing Mode: How to process extracted content with LLMs
# Options:
#   - text_llm: Send all text (direct + OCR) to text LLM (default)
#   - vision_llm: Send all images to vision LLM
#   - multimodal: Send text + images together to vision LLM in single call
#   - dual_llm: Send text to text LLM + images to vision LLM separately, then merge
LLM_PROCESSING_MODE=multimodal

# OCR Engine: Which OCR engine to use when OCR is needed
# Options: tesseract, gcv
# Note: Only used when EXTRACTION_METHOD requires OCR (ocr_all, ocr_images_only)
# Note: vision_all and multimodal don't use OCR
OCR_ENGINE=tesseract

# ============================================================================
# Tesseract OCR Configuration
# ============================================================================

# Tesseract executable path (optional, for non-standard installations)
# Windows example: C:\Program Files\Tesseract-OCR\tesseract.exe
# Linux example: /usr/bin/tesseract (usually in PATH, can omit)
# Docker: Usually in PATH, no configuration needed
# Leave empty to use system PATH
TESSERACT_CMD=

# Tesseract language(s) for OCR
# Use ISO 639-2 language codes (e.g., "eng", "eng+fra" for multiple languages)
# Default: "eng" (English)
TESSERACT_LANG=eng

# Tesseract data directory (optional, for custom tessdata location)
# Windows example: C:\Program Files\Tesseract-OCR\tessdata
# Linux example: /usr/share/tesseract-ocr/5/tessdata (usually default, can omit)
# Docker: Usually default, no configuration needed
# Leave empty to use default location
TESSDATA_PREFIX=

# ============================================================================
# Google Cloud Vision Configuration (Optional)
# ============================================================================

# Path to Google Cloud Vision service account credentials JSON file
# Required only if using OCR_ENGINE=gcv
# GCV_CREDENTIALS_PATH=/path/to/service-account.json

# Google Cloud Project ID (optional, usually auto-detected from credentials)
# GCV_PROJECT_ID=your-project-id

# ============================================================================
# PDF Preprocessing Configuration
# ============================================================================

# DPI for rendering PDF pages as images (150, 300, 600)
# Higher DPI = better quality but larger files
# 300 DPI is optimal for OCR (balance between quality and size)
PDF_PREPROCESSING_DPI=300

# Enable OpenCV preprocessing for scanned PDFs (master switch)
# Options: true, false
ENABLE_IMAGE_PREPROCESSING=true

# Individual preprocessing steps (can be toggled)
ENABLE_DESKEW=true      # Correct page rotation
ENABLE_DENOISE=true     # Remove speckle noise
ENABLE_ENHANCE=true     # Apply CLAHE contrast enhancement
ENABLE_BINARIZE=true    # Adaptive thresholding to black/white

# ============================================================================
# Retry Configuration
# ============================================================================

# Maximum number of retry attempts for API calls
API_MAX_RETRIES=3

# Initial retry delay in seconds (exponential backoff)
API_RETRY_INITIAL_DELAY=1.0

# Maximum retry delay in seconds (caps exponential backoff)
API_RETRY_MAX_DELAY=30.0

# ============================================================================
# Logging Configuration
# ============================================================================

# Overall log level
# Options: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# File logging
LOG_FILE_ENABLED=true
LOG_FILE_PATH=./logs
LOG_FILE_FORMAT=text              # Options: text, json
LOG_FILE_ROTATION_DAYS=30
LOG_FILE_MAX_SIZE_MB=10

# Console logging
LOG_CONSOLE_ENABLED=true
LOG_CONSOLE_FORMAT=text           # Options: text, json

# Module-specific log levels (optional overrides)
# LOG_LEVEL_EXTRACTORS=DEBUG
# LOG_LEVEL_AI=INFO
# LOG_LEVEL_OCR=WARNING

# ============================================================================
# Persistence & Storage Configuration
# ============================================================================

# SQLite database path (default: ./storage/msa_extractor.db)
# Database stores job records, extraction results (JSON), and logs
DB_PATH=./storage/msa_extractor.db

# Uploads directory (for temporary PDFs/DOCX files)
# Files are stored here during extraction, then cleaned up after N days
UPLOADS_DIR=./uploads

# Results directory (for legacy mode - file-based JSON storage)
# Only used when CLI is run with --legacy flag
# Default and API always use database storage
RESULTS_DIR=./results

# Logs directory (for legacy mode - file-based log storage)
# Only used when CLI is run with --legacy flag
# Default and API always use database storage
LOGS_DIR=./logs

# Output directory for extracted JSON files (legacy, for batch processing)
OUTPUT_DIR=./results

# Cleanup configuration for uploaded PDFs
CLEANUP_PDF_DAYS=7              # Delete PDFs older than N days
CLEANUP_PDF_MAX_COUNT=1000      # Max PDFs to keep
CLEANUP_PDF_MIN_COUNT=500       # Min PDFs to keep before cleanup

# ============================================================================
# GCP Configuration (Future Iterations - TODO)
# ============================================================================

# Google Cloud Project ID (for future GCS and Cloud SQL integration)
# GCP_PROJECT_ID=your-project-id

# Google Cloud Storage bucket (for future PDF storage)
# GCP_STORAGE_BUCKET=your-bucket-name

# Cloud SQL instance (for future database migration)
# GCP_CLOUD_SQL_INSTANCE=your-instance-name

# Enable GCS storage (future feature)
# USE_GCS=false

# Enable Cloud SQL (future feature)
# USE_CLOUD_SQL=false

# ============================================================================
# Advanced Configuration
# ============================================================================

# Maximum text length for LLM processing (characters)
# For longer docs, implement chunking + aggregation (deferred to next iteration)
# MAX_TEXT_LENGTH=50000

# Maximum length per metadata field (characters)
# Each field value must not exceed this limit (default: 1000)
# MAX_FIELD_LENGTH=1000

# ============================================================================
# Common Configuration Examples
# ============================================================================

# Example 1: Text-only PDF → Vision LLM
# EXTRACTION_METHOD=vision_all
# LLM_PROCESSING_MODE=vision_llm

# Example 2: Mixed PDF → OCR Image Pages → Text LLM
# EXTRACTION_METHOD=ocr_images_only
# LLM_PROCESSING_MODE=text_llm
# OCR_ENGINE=tesseract

# Example 3: Mixed PDF → Text + Images → Multimodal Vision LLM
# EXTRACTION_METHOD=hybrid
# LLM_PROCESSING_MODE=multimodal

# Example 4: Mixed PDF → Text to Text LLM + Images to Vision LLM
# EXTRACTION_METHOD=hybrid
# LLM_PROCESSING_MODE=dual_llm

# Example 5: Fully Scanned PDF → OCR → Text LLM
# EXTRACTION_METHOD=ocr_all
# LLM_PROCESSING_MODE=text_llm
# OCR_ENGINE=tesseract

# Example 6: Fully Scanned PDF → Vision LLM Direct
# EXTRACTION_METHOD=vision_all
# LLM_PROCESSING_MODE=vision_llm

# Example 7: Production API with Authentication
# API_ENABLE_AUTH=true
# API_KEY=your-strong-random-key-here
# API_WORKERS=4
# API_RELOAD=false
# MAX_UPLOAD_SIZE_MB=50

# ============================================================================
# Notes
# ============================================================================
# - All paths use forward slashes or pathlib (cross-platform compatible)
# - Boolean values: use "true" or "false" (case-insensitive)
# - Empty values use system defaults
# - See docs/architecture/EXTRACTION_ARCHITECTURE.md for extraction methods
# - See docs/planning/API_DESIGN.md for API authentication details
# - See docs/setup/configuration.md for complete configuration reference
# - See docs/setup/LINUX_AND_DOCKER_SETUP.md for Docker configuration
# ============================================================================