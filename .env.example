# ============================================================================
# MSA Metadata Extractor - Environment Variables Configuration
# ============================================================================
# Copy this file to .env and update with your actual values
# Never commit .env to version control (it's in .gitignore)
# ============================================================================

# ============================================================================
# REQUIRED: API Configuration
# ============================================================================

# Gemini API Key (REQUIRED)
# Get your API key from: https://makersuite.google.com/app/apikey
GEMINI_API_KEY=

# ============================================================================
# Gemini Model Configuration
# ============================================================================

# Text LLM model for metadata extraction from text
# Options: gemini-2.5-pro, gemini-2.5-flash, gemini-1.5-pro, gemini-1.5-flash
GEMINI_TEXT_MODEL=gemini-2.5-pro

# Vision LLM model for image-based extraction and multimodal input
# Options: gemini-2.5-pro, gemini-2.5-flash, gemini-1.5-pro, gemini-1.5-flash
GEMINI_VISION_MODEL=gemini-2.5-pro

# ============================================================================
# Extraction Configuration (NEW ARCHITECTURE)
# ============================================================================

# Extraction Method: How to extract content from PDF pages
# Options:
#   - text_direct: Extract text directly from text pages, ignore image pages
#   - ocr_all: Convert all pages to images and run OCR on all pages
#   - ocr_images_only: Extract text from text pages + OCR only image pages (default)
#   - vision_all: Convert all pages to images (no OCR, for vision LLM)
#   - hybrid: Extract text from text pages + convert image pages to images (flexible)
EXTRACTION_METHOD=hybrid

# LLM Processing Mode: How to process extracted content with LLMs
# Options:
#   - text_llm: Send all text (direct + OCR) to text LLM (default)
#   - vision_llm: Send all images to vision LLM
#   - multimodal: Send text + images together to vision LLM in single call
#   - dual_llm: Send text to text LLM + images to vision LLM separately, then merge
LLM_PROCESSING_MODE=multimodal

# OCR Engine: Which OCR engine to use when OCR is needed
# Options: tesseract, gcv
# Note: Only used when EXTRACTION_METHOD requires OCR (ocr_all, ocr_images_only)
# Note: vision_all and multimodal don't use OCR
OCR_ENGINE=tesseract

# ============================================================================
# Tesseract OCR Configuration
# ============================================================================

# Tesseract executable path (optional, for non-standard installations)
# Windows example: C:\Program Files\Tesseract-OCR\tesseract.exe
# Linux example: /usr/bin/tesseract (usually in PATH, can omit)
# Docker: Usually in PATH, no configuration needed
# Leave empty to use system PATH
TESSERACT_CMD=

# Tesseract language(s) for OCR
# Use ISO 639-2 language codes (e.g., "eng", "eng+fra" for multiple languages)
# Default: "eng" (English)
TESSERACT_LANG=eng

# Tesseract data directory (optional, for custom tessdata location)
# Windows example: C:\Program Files\Tesseract-OCR\tessdata
# Linux example: /usr/share/tesseract-ocr/5/tessdata (usually default, can omit)
# Docker: Usually default, no configuration needed
# Leave empty to use default location
TESSDATA_PREFIX=

# ============================================================================
# Google Cloud Vision Configuration (Optional)
# ============================================================================

# Path to Google Cloud Vision service account credentials JSON file
# Required only if using OCR_ENGINE=gcv
# GCV_CREDENTIALS_PATH=/path/to/service-account.json

# Google Cloud Project ID (optional, usually auto-detected from credentials)
# GCV_PROJECT_ID=your-project-id

# ============================================================================
# PDF Preprocessing Configuration
# ============================================================================

# DPI for rendering PDF pages as images (150, 300, 600)
# Higher DPI = better quality but larger files
# 300 DPI is optimal for OCR (balance between quality and size)
PDF_PREPROCESSING_DPI=300

# Enable OpenCV preprocessing for scanned PDFs (master switch)
# Options: true, false
ENABLE_IMAGE_PREPROCESSING=true

# Individual preprocessing steps (can be toggled)
ENABLE_DESKEW=true      # Correct page rotation
ENABLE_DENOISE=true     # Remove speckle noise
ENABLE_ENHANCE=true     # Apply CLAHE contrast enhancement
ENABLE_BINARIZE=true    # Adaptive thresholding to black/white

# ============================================================================
# Retry Configuration
# ============================================================================

# Maximum number of retry attempts for API calls
API_MAX_RETRIES=3

# Initial retry delay in seconds (exponential backoff)
API_RETRY_INITIAL_DELAY=1.0

# Maximum retry delay in seconds (caps exponential backoff)
API_RETRY_MAX_DELAY=30.0

# ============================================================================
# Logging Configuration
# ============================================================================

# Overall log level
# Options: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# File logging
LOG_FILE_ENABLED=true
LOG_FILE_PATH=./logs
LOG_FILE_FORMAT=text              # Options: text, json
LOG_FILE_ROTATION_DAYS=30
LOG_FILE_MAX_SIZE_MB=10

# Console logging
LOG_CONSOLE_ENABLED=true
LOG_CONSOLE_FORMAT=text           # Options: text, json

# Module-specific log levels (optional overrides)
# LOG_LEVEL_EXTRACTORS=DEBUG
# LOG_LEVEL_AI=INFO
# LOG_LEVEL_OCR=WARNING

# ============================================================================
# Paths & Storage
# ============================================================================

# Output directory for extracted JSON files
# Default: ./results
OUTPUT_DIR=./results

# SQLite database path (if using database storage)
# Default: ./msa_extractor.db
DB_PATH=./msa_extractor.db

# ============================================================================
# Advanced Configuration
# ============================================================================

# Maximum text length for LLM processing (characters)
# For longer docs, implement chunking + aggregation (deferred to next iteration)
# MAX_TEXT_LENGTH=50000

# ============================================================================
# Common Configuration Examples
# ============================================================================

# Example 1: Text-only PDF → Vision LLM
# EXTRACTION_METHOD=vision_all
# LLM_PROCESSING_MODE=vision_llm

# Example 2: Mixed PDF → OCR Image Pages → Text LLM
# EXTRACTION_METHOD=ocr_images_only
# LLM_PROCESSING_MODE=text_llm
# OCR_ENGINE=tesseract

# Example 3: Mixed PDF → Text + Images → Multimodal Vision LLM
# EXTRACTION_METHOD=hybrid
# LLM_PROCESSING_MODE=multimodal

# Example 4: Mixed PDF → Text to Text LLM + Images to Vision LLM
# EXTRACTION_METHOD=hybrid
# LLM_PROCESSING_MODE=dual_llm

# Example 5: Fully Scanned PDF → OCR → Text LLM
# EXTRACTION_METHOD=ocr_all
# LLM_PROCESSING_MODE=text_llm
# OCR_ENGINE=tesseract

# Example 6: Fully Scanned PDF → Vision LLM Direct
# EXTRACTION_METHOD=vision_all
# LLM_PROCESSING_MODE=vision_llm

# ============================================================================
# Notes
# ============================================================================
# - All paths use forward slashes or pathlib (cross-platform compatible)
# - Boolean values: use "true" or "false" (case-insensitive)
# - Empty values use system defaults
# - See docs/EXTRACTION_ARCHITECTURE.md for detailed documentation
# - See docs/LINUX_AND_DOCKER_SETUP.md for Docker configuration
# ============================================================================